{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of a dog breed classification model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a small dataset of 133 types of dogs. It is necessary to build a classifier of these breeds. Since the dataset is too small to train the model from scratch, we will use transfer lerning. Let's test the ResNet and MobileNet models. I will compare the most accurate ResNet101 model with the tiny and fast MobileNet v3 (Large) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JrsnGepvxFF",
    "outputId": "db4c43af-e952-408f-be5e-fc6f55c801ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To augment the data, I will use a RandomHorizontalFlip and ColorJitter. I chose a batch size equal to 256 because this value shows good convergence results for image classifiers. I use three subsets of the data for training, testing and validating overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hfThwZMvz5A"
   },
   "outputs": [],
   "source": [
    "from os.path import join as path\n",
    "from torchvision.transforms import (Compose, Resize, CenterCrop, ColorJitter,\n",
    "                                    RandomHorizontalFlip, ToTensor, Normalize)\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tform = {'train': Compose([\n",
    "                           Resize(256),\n",
    "                           CenterCrop(227),\n",
    "                           RandomHorizontalFlip(),\n",
    "                           ColorJitter(0.4, 0.4, 0.4),\n",
    "                           ToTensor(),\n",
    "                           Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225))\n",
    "                           ]),\n",
    "         'valid': Compose([\n",
    "                           Resize(256),\n",
    "                           CenterCrop(227),\n",
    "                           ToTensor(),\n",
    "                           Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225))]),\n",
    "         'test': Compose([\n",
    "                           Resize(256),\n",
    "                           CenterCrop(227),\n",
    "                           ToTensor(),\n",
    "                           Normalize((0.485, 0.456, 0.406),\n",
    "                                     (0.229, 0.224, 0.225))])}\n",
    "\n",
    "data_dir = '/content/drive/MyDrive/Colab Notebooks/dogImages'\n",
    "dataset = {x: ImageFolder(path(data_dir, x), tform[x]) for x in tform.keys()}\n",
    "loaders = {x: DataLoader(dataset=dataset[x],\n",
    "                         batch_size=256,\n",
    "                         shuffle=(x=='train'),\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         drop_last=False) for x in dataset.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the cross-entropy loss function for multiclass classification and the Adam algorithm, since it shows good convergence results with ease of setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rlQH4RCvtes"
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to change the output layer of the classifier in accordance with the task. In addition, I will add a batch normalization layer for fast model convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqky8PgGv8U3"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, BatchNorm1d\n",
    "from torch import cuda\n",
    "from torchvision.models import resnext101_32x8d\n",
    "\n",
    "model = resnext101_32x8d(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = Sequential(\n",
    "    BatchNorm1d(model.fc.in_features),\n",
    "    Linear(model.fc.in_features, 133, bias=True))\n",
    "\n",
    "use_cuda = cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model quickly overfits so I will use a small number of epochs. Therefore, with the help of the planner, I will decrease the learning rate non-linearly to achieve the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_YdiLNZv_LN"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[8, 10, 11], gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function consists of two stages of training and validation. Error values are displayed every 10 batches. The model will be saved when the minimum loss is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torch import save, load\n",
    "\n",
    "\n",
    "def train(model, loaders, criterion, optimizer, epochs):\n",
    "    min_loss = 2**64\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch: {epoch+1}')\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            elif phase == 'valid':\n",
    "                model.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            for idx, (data, cls) in enumerate(loaders[phase]):\n",
    "                if use_cuda:\n",
    "                    data = data.cuda()\n",
    "                    cls = cls.cuda()\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                loss = criterion(model(data), cls)\n",
    "                \n",
    "                epoch_loss += loss.item() * data.size(0)\n",
    "                if not idx % 10:\n",
    "                    print(loss.item())\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            epoch_loss /= len(loaders[phase].dataset)\n",
    "\n",
    "            print(f'epoch {epoch+1}: {phase} phase is completed. mean loss: {epoch_loss}')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if min_loss > epoch_loss:\n",
    "            save(model.state_dict(), 'resnet_model.pt')\n",
    "            min_loss = epoch_loss\n",
    "            print(f'minimum loss: {min_loss}. Model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start a training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwNNiVWYwDPP",
    "outputId": "ae01ca78-0a0f-4f49-c372-94d080be27f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "5.176853179931641\n",
      "1.0089534521102905\n",
      "0.5885645747184753\n",
      "epoch 1: train phase is completed. mean loss: 1.4243048998410117\n",
      "0.3846698999404907\n",
      "epoch 1: valid phase is completed. mean loss: 0.45516235421517653\n",
      "minimum loss: 0.45516235421517653. Model saved\n",
      "epoch: 2\n",
      "0.2627578675746918\n",
      "0.18864288926124573\n",
      "0.24788738787174225\n",
      "epoch 2: train phase is completed. mean loss: 0.2520779275965548\n",
      "0.2616994380950928\n",
      "epoch 2: valid phase is completed. mean loss: 0.32592301682797736\n",
      "minimum loss: 0.32592301682797736. Model saved\n",
      "epoch: 3\n",
      "0.18819408118724823\n",
      "0.15649135410785675\n",
      "0.20243898034095764\n",
      "epoch 3: train phase is completed. mean loss: 0.16111699854899308\n",
      "0.2419833093881607\n",
      "epoch 3: valid phase is completed. mean loss: 0.296657872271395\n",
      "minimum loss: 0.296657872271395. Model saved\n",
      "epoch: 4\n",
      "0.10141529142856598\n",
      "0.1573948711156845\n",
      "0.12641480565071106\n",
      "epoch 4: train phase is completed. mean loss: 0.12540101578492605\n",
      "0.23808136582374573\n",
      "epoch 4: valid phase is completed. mean loss: 0.3101703377897868\n",
      "epoch: 5\n",
      "0.08495897799730301\n",
      "0.09647951275110245\n",
      "0.10037096589803696\n",
      "epoch 5: train phase is completed. mean loss: 0.100209910186108\n",
      "0.22919978201389313\n",
      "epoch 5: valid phase is completed. mean loss: 0.306273458746379\n",
      "epoch: 6\n",
      "0.10583842545747757\n",
      "0.0800202339887619\n",
      "0.06925777345895767\n",
      "epoch 6: train phase is completed. mean loss: 0.07832809398898821\n",
      "0.23303180932998657\n",
      "epoch 6: valid phase is completed. mean loss: 0.3156948691713596\n",
      "epoch: 7\n",
      "0.05638211965560913\n",
      "0.046073924750089645\n",
      "0.061882033944129944\n",
      "epoch 7: train phase is completed. mean loss: 0.06857735714512671\n",
      "0.2529737949371338\n",
      "epoch 7: valid phase is completed. mean loss: 0.3279894507216836\n",
      "epoch: 8\n",
      "0.039593592286109924\n",
      "0.07440266758203506\n",
      "0.04199735075235367\n",
      "epoch 8: train phase is completed. mean loss: 0.055930519898137646\n",
      "0.23175396025180817\n",
      "epoch 8: valid phase is completed. mean loss: 0.29706836175061985\n",
      "epoch: 9\n",
      "0.03550281748175621\n",
      "0.0443418063223362\n",
      "0.0340225026011467\n",
      "epoch 9: train phase is completed. mean loss: 0.04296461236467975\n",
      "0.22963471710681915\n",
      "epoch 9: valid phase is completed. mean loss: 0.29656997262360807\n",
      "minimum loss: 0.29656997262360807. Model saved\n",
      "epoch: 10\n",
      "0.04863099008798599\n",
      "0.04687335714697838\n",
      "0.05554322153329849\n",
      "epoch 10: train phase is completed. mean loss: 0.04464816084343516\n",
      "0.23075471818447113\n",
      "epoch 10: valid phase is completed. mean loss: 0.2950344224176007\n",
      "minimum loss: 0.2950344224176007. Model saved\n",
      "epoch: 11\n",
      "0.03073701448738575\n",
      "0.04263857379555702\n",
      "0.03498626872897148\n",
      "epoch 11: train phase is completed. mean loss: 0.03661859217071962\n",
      "0.2331363558769226\n",
      "epoch 11: valid phase is completed. mean loss: 0.29256791461727577\n",
      "minimum loss: 0.29256791461727577. Model saved\n",
      "epoch: 12\n",
      "0.04019246622920036\n",
      "0.03965816646814346\n",
      "0.04247365519404411\n",
      "epoch 12: train phase is completed. mean loss: 0.034001399326824146\n",
      "0.22942866384983063\n",
      "epoch 12: valid phase is completed. mean loss: 0.2928196170372877\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "\n",
    "train(model, loaders, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCe1-IT0wMoC",
    "outputId": "d4f2bd92-6aa1-46b0-aa84-7840a51cf70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30240592403274974, accuracy: 91.02870178222656%\n"
     ]
    }
   ],
   "source": [
    "from torch import save, load\n",
    "from torch import cuda\n",
    "\n",
    "def test(model, loaders, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0\n",
    "    for data, cls in loaders['test']:\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            cls = cls.cuda()\n",
    "\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, cls)\n",
    "        pred = pred.data.max(1)[1]\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        accuracy += sum(pred == cls.data)\n",
    "        total += data.size(0)\n",
    "\n",
    "    running_loss /= len(loaders['test'].dataset)\n",
    "    accuracy /= total\n",
    "    print(f'loss: {running_loss}, accuracy: {accuracy*100}%')\n",
    "\n",
    "\n",
    "params = load('resnet_model.pt', map_location='cuda' if use_cuda else 'cpu')\n",
    "model.load_state_dict(params)\n",
    "\n",
    "test(model, loaders, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVfgUpFms3ik"
   },
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a MobileNet. I'll replace the Dropout layer with a normalization layer for quick convergence of training. I found that for this task, initializing the last layer with zero values is the most opportunely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9Ni3vbhYtXta"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_large\n",
    "\n",
    "model = mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[2] = BatchNorm1d(1280)\n",
    "model.classifier[3] = Linear(1280, 133, bias=True)\n",
    "\n",
    "model.classifier[3].weight.data.fill_(0.0)\n",
    "model.classifier[3].bias.data.fill_(0.0)\n",
    "\n",
    "use_cuda = cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm using a learning algorithm that stops fast enough. The model with batch normalization is overfitting too quickly and therefore, without updating the minimum loss, the algorithm will decrease the learning rate and stop earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5DpJ9Uow42h",
    "outputId": "f0ce8688-bccb-47e6-d3be-6a9038be409a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "learning rate: 0.001\n",
      "4.890349864959717\n",
      "2.933051347732544\n",
      "2.005187511444092\n",
      "epoch 1: train phase is completed. mean loss: 2.897489925344547\n",
      "0.8594317436218262\n",
      "epoch 1: valid phase is completed. mean loss: 1.14082393132284\n",
      "minimum loss: 1.14082393132284. Model saved\n",
      "epoch: 2\n",
      "learning rate: 0.001\n",
      "1.2356833219528198\n",
      "1.0186142921447754\n",
      "0.9835569858551025\n",
      "epoch 2: train phase is completed. mean loss: 1.0377937084186577\n",
      "0.5307849645614624\n",
      "epoch 2: valid phase is completed. mean loss: 0.7435367631341169\n",
      "minimum loss: 0.7435367631341169. Model saved\n",
      "epoch: 3\n",
      "learning rate: 0.001\n",
      "0.7315253019332886\n",
      "0.683749258518219\n",
      "0.6761021614074707\n",
      "epoch 3: train phase is completed. mean loss: 0.6562500330502402\n",
      "0.45249080657958984\n",
      "epoch 3: valid phase is completed. mean loss: 0.651704239060065\n",
      "minimum loss: 0.651704239060065. Model saved\n",
      "epoch: 4\n",
      "learning rate: 0.001\n",
      "0.49228665232658386\n",
      "0.4172075092792511\n",
      "0.40234169363975525\n",
      "epoch 4: train phase is completed. mean loss: 0.47058061189994127\n",
      "0.42309293150901794\n",
      "epoch 4: valid phase is completed. mean loss: 0.626211089359786\n",
      "minimum loss: 0.626211089359786. Model saved\n",
      "epoch: 5\n",
      "learning rate: 0.001\n",
      "0.36823225021362305\n",
      "0.4995180666446686\n",
      "0.35045313835144043\n",
      "epoch 5: train phase is completed. mean loss: 0.36167572065741715\n",
      "0.4298277497291565\n",
      "epoch 5: valid phase is completed. mean loss: 0.6268421975438466\n",
      "epoch: 6\n",
      "learning rate: 0.0005\n",
      "0.23873034119606018\n",
      "0.30731168389320374\n",
      "0.2641150951385498\n",
      "epoch 6: train phase is completed. mean loss: 0.2826200972060244\n",
      "0.44045090675354004\n",
      "epoch 6: valid phase is completed. mean loss: 0.6323961676237826\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "def train(model, loaders, criterion, optimizer, epochs):\n",
    "    min_loss = 2**64\n",
    "    useless_epochs = 0\n",
    "    default_lr = optimizer.defaults['lr']\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch: {epoch+1}')\n",
    "        print('learning rate: {}'.format(optimizer.defaults['lr']))\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            elif phase == 'valid':\n",
    "                model.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            for idx, (data, cls) in enumerate(loaders[phase]):\n",
    "                if use_cuda:\n",
    "                    data = data.cuda()\n",
    "                    cls = cls.cuda()\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                loss = criterion(model(data), cls)\n",
    "                \n",
    "                epoch_loss += loss.item() * data.size(0)\n",
    "                if not idx % 10:\n",
    "                    print(loss.item())\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            epoch_loss /= len(loaders[phase].dataset)\n",
    "\n",
    "            print(f'epoch {epoch+1}: {phase} phase is completed. mean loss: {epoch_loss}')\n",
    "\n",
    "        useless_epochs += 1\n",
    "\n",
    "        if min_loss > epoch_loss:\n",
    "            save(model.state_dict(), 'mobilenet_model.pt')\n",
    "            min_loss = epoch_loss\n",
    "            print(f'minimum loss: {min_loss}. Model saved')\n",
    "            useless_epochs = 0\n",
    "        \n",
    "        if useless_epochs > 0:\n",
    "            if useless_epochs >= 2:\n",
    "                optimizer.defaults['lr'] = default_lr\n",
    "                break\n",
    "              \n",
    "            optimizer.defaults['lr'] *= 0.5\n",
    "\n",
    "train(model, loaders, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ym8w2aT8xukv",
    "outputId": "7c2c3acc-5b59-46db-cf4e-e4ec42eb5de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6637992391175631, accuracy: 82.29664611816406%\n"
     ]
    }
   ],
   "source": [
    "def test(model, loaders, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0\n",
    "    for data, cls in loaders['test']:\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            cls = cls.cuda()\n",
    "\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, cls)\n",
    "        pred = pred.data.max(1)[1]\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        accuracy += sum(pred == cls.data)\n",
    "        total += data.size(0)\n",
    "\n",
    "    running_loss /= len(loaders['test'].dataset)\n",
    "    accuracy /= total\n",
    "    print(f'loss: {running_loss}, accuracy: {accuracy*100}%')\n",
    "\n",
    "\n",
    "params = load('mobilenet_model.pt', map_location='cuda' if use_cuda else 'cpu')\n",
    "model.load_state_dict(params)\n",
    "\n",
    "test(model, loaders, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models learned quickly enough. Due to the small dataset, a fast overfitting is observed. The use of a learning strategy minimized this tendency. Thus obtained models with accuracies of 91 and 82.3 percent with the size of models 333 MiB and 17 MiB, respectively. It can be seen that the model built with MobileNet is more preferable in terms of performance and memory."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6-WFHB36Nude"
   ],
   "name": "model_development.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2af815972b734272b83547d8c43e9702": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3258b1416338430d9e9cc9c2babd9e7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4d08f95fad67456f8db916b9399e0702": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9131857aa084240afd10313102f7bec",
      "max": 356082095,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3258b1416338430d9e9cc9c2babd9e7c",
      "value": 356082095
     }
    },
    "51ab1525364940c6ab3211d820e87969": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92cee83c2efa4ed9b75a8ab9ecf6e3ce",
      "placeholder": "​",
      "style": "IPY_MODEL_2af815972b734272b83547d8c43e9702",
      "value": " 340M/340M [00:04&lt;00:00, 88.8MB/s]"
     }
    },
    "5495cb73c1124ef793d2b8c8f9709e4e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92cee83c2efa4ed9b75a8ab9ecf6e3ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c70f5e479bc1483ba75696ad227c3836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d08f95fad67456f8db916b9399e0702",
       "IPY_MODEL_51ab1525364940c6ab3211d820e87969"
      ],
      "layout": "IPY_MODEL_5495cb73c1124ef793d2b8c8f9709e4e"
     }
    },
    "d9131857aa084240afd10313102f7bec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
